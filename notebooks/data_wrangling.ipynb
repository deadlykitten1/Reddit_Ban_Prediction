{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fetch an OAUTH Token. It is only valid for 2 hours and will need to be re-requested when it expires.\n",
    "\n",
    "# The following code curtesy of James Briggs: https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c\n",
    "\n",
    "# note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'\n",
    "auth = requests.auth.HTTPBasicAuth('fOIoNDAQnOFBiQ5RM9CEuA', 'Rb9whMn_xOwNVra9usbbEPYkVtMqvw')\n",
    "\n",
    "# here we pass our login method (password), username, and password\n",
    "data = {'grant_type': 'password',\n",
    "        'username': 'flatest_iron',\n",
    "        'password': 'FlatironPassword19!'}\n",
    "\n",
    "# setup our header info, which gives reddit a brief description of our app\n",
    "headers = {'User-Agent': 'MyBot'}\n",
    "\n",
    "# send our request for an OAuth token\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "# convert response to JSON and pull access_token value\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "# add authorization to our headers dictionary\n",
    "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# while the token is valid (~2 hours) we just add headers=headers to our requests\n",
    "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a test to see how this works in general\n",
    "\n",
    "# Get the top 25 posts of all time from r/python\n",
    "#TODO: It might be worth it to change which posts are pulled: maybe hot posts are more indicative, but for now we're doing this\n",
    "response = requests.get(\"https://oauth.reddit.com/r/python/top/?t=all\", headers=headers)\n",
    "\n",
    "# python_df = pd.DataFrame()\n",
    "\n",
    "# #We can add to this if need be; there is a lot of data that isn't being captured here\n",
    "# for post in response.json()['data']['children']:\n",
    "#     python_df = python_df.append({\n",
    "#         'subreddit' : post['data']['subreddit'],\n",
    "#         'title' : post['data']['title'],\n",
    "#         'text' : post['data']['selftext'],\n",
    "#         'upvote_ratio' : post['data']['upvote_ratio'],\n",
    "#         'url_overriden_by_dest' : post['data']['url_overridden_by_dest'] #I think this is the image url\n",
    "#     }, ignore_index = True)\n",
    "\n",
    "# python_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['approved_at_utc', 'subreddit', 'selftext', 'author_fullname', 'saved', 'mod_reason_title', 'gilded', 'clicked', 'title', 'link_flair_richtext', 'subreddit_name_prefixed', 'hidden', 'pwls', 'link_flair_css_class', 'downs', 'thumbnail_height', 'top_awarded_type', 'hide_score', 'name', 'quarantine', 'link_flair_text_color', 'upvote_ratio', 'author_flair_background_color', 'ups', 'total_awards_received', 'media_embed', 'thumbnail_width', 'author_flair_template_id', 'is_original_content', 'user_reports', 'secure_media', 'is_reddit_media_domain', 'is_meta', 'category', 'secure_media_embed', 'link_flair_text', 'can_mod_post', 'score', 'approved_by', 'is_created_from_ads_ui', 'author_premium', 'thumbnail', 'edited', 'author_flair_css_class', 'author_flair_richtext', 'gildings', 'post_hint', 'content_categories', 'is_self', 'subreddit_type', 'created', 'link_flair_type', 'wls', 'removed_by_category', 'banned_by', 'author_flair_type', 'domain', 'allow_live_comments', 'selftext_html', 'likes', 'suggested_sort', 'banned_at_utc', 'url_overridden_by_dest', 'view_count', 'archived', 'no_follow', 'is_crosspostable', 'pinned', 'over_18', 'preview', 'all_awardings', 'awarders', 'media_only', 'link_flair_template_id', 'can_gild', 'spoiler', 'locked', 'author_flair_text', 'treatment_tags', 'visited', 'removed_by', 'mod_note', 'distinguished', 'subreddit_id', 'author_is_blocked', 'mod_reason_by', 'num_reports', 'removal_reason', 'link_flair_background_color', 'id', 'is_robot_indexable', 'report_reasons', 'author', 'discussion_type', 'num_comments', 'send_replies', 'whitelist_status', 'contest_mode', 'mod_reports', 'author_patreon_flair', 'author_flair_text_color', 'permalink', 'parent_whitelist_status', 'stickied', 'url', 'subreddit_subscribers', 'created_utc', 'num_crossposts', 'media', 'is_video'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['data']['children'][0]['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of a subreddits that we want to fetch the top posts for\n",
    "\n",
    "# There might be a better way to do this, but for right now, I'm just gonna do it manually\n",
    "# My reasoning for this is that I can grab some less popular reddits that some of the listings\n",
    "# Right now I have some blatantly right, blatantly left, and apolitical subreddits\n",
    "\n",
    "# Hopefully I don't introduce any implicit bias into my model lol\n",
    "subreddits = [\n",
    "    #Quarantined subreddits\n",
    "    'TheRedPill',\n",
    "\n",
    "    #apolitical (I think)\n",
    "    'BlackPeopleTwitter',\n",
    "    'WhitePeopleTwitter',\n",
    "    'politics',\n",
    "    'law',\n",
    "    'news',\n",
    "    'worldnews',\n",
    "    'Jokes',\n",
    "    'funny',\n",
    "    'gaming',\n",
    "    'Games',\n",
    "    'technology',\n",
    "    'tech',\n",
    "    'technews',\n",
    "    'gadgets',\n",
    "    'space',\n",
    "    'science',\n",
    "    'nextfuckinglevel',\n",
    "    'MurderedByWords',\n",
    "    'mildlyinteresting',\n",
    "    'Damnthatsinteresting',\n",
    "    'mildlyinfuriating',\n",
    "    'wallstreetbets',\n",
    "    'Superstonk',\n",
    "    'shitposting',\n",
    "    'pcmasterrace',\n",
    "    'teenagers',\n",
    "    'PublicFreakout',\n",
    "    'memes',\n",
    "    'AskReddit',\n",
    "    'AskAnAmerican',\n",
    "    'GamingCircleJerk',\n",
    "    'nottheonion',\n",
    "    'gatesopencomeonin',\n",
    "    'wholesomememes',\n",
    "    'wholesome',\n",
    "    'interestingasfuck',\n",
    "    'PoliticalCompassMemes',\n",
    "    'PoliticalHumor',\n",
    "    'AskMen',\n",
    "    'AskWomen',\n",
    "    'TooAfraidToAsk',\n",
    "    'MadeMeSmile',\n",
    "    'rareinsults',\n",
    "    'UFOs',\n",
    "    'HighStrangeness',\n",
    "    'todayilearned',\n",
    "    'RoastMe',\n",
    "    'CryptoCurrency',\n",
    "    'Wellthatsucks',\n",
    "    'barstoolsports',\n",
    "    'awfuleverything',\n",
    "    'unpopularopinion',\n",
    "    'atheism',\n",
    "    'Christianity',\n",
    "    'Catholicism',\n",
    "    'changemyview',\n",
    "    'Coronavirus',\n",
    "    'covid19',\n",
    "    'coronavirusnyc',\n",
    "    'Masks4All',\n",
    "    'consipiratard',\n",
    "    'environment',\n",
    "    'TrollXChromosomes',\n",
    "    'TrollYChromosome',\n",
    "    'WikiLeaks',\n",
    "    '4chan',\n",
    "    'greentext',\n",
    "    'NoStupidQuestions',\n",
    "    'offmychest',\n",
    "    'texas',\n",
    "    'terriblefacebookmemes',\n",
    "    'insanepeoplefacebook',\n",
    "    'ShitMomGroupsSay',\n",
    "    'masskillers',\n",
    "    'Parenting',\n",
    "    'Marriage',\n",
    "    'neoliberal',\n",
    "    'spacex',\n",
    "    'savedyouaclick',\n",
    "    'socialmedia',\n",
    "    'moderatepolitics',\n",
    "    'virginvschad',\n",
    "    'CoronavirusCircleJerk',\n",
    "\n",
    "    #left (I think)\n",
    "    'antiwork',\n",
    "    'Anticonsumption',\n",
    "    'SelfAwarewolves',\n",
    "    'niceguys',\n",
    "    'onejoke',\n",
    "    'Feminism',\n",
    "    'WitchesVsPatriarchy',\n",
    "    'AreTheStraightsOK',\n",
    "    'ToiletPaperUSA',\n",
    "    'LeopardsAteMyFace',\n",
    "    'TwoXChromosomes',\n",
    "    'Anarchism',\n",
    "    'TopMindsOfReddit',\n",
    "    'esist',\n",
    "    'MarchAgainstNazis',\n",
    "    'exredpill',\n",
    "    'MensLib',\n",
    "    'lgbt',\n",
    "    'gay',\n",
    "    'bisexual',\n",
    "    'AgainstHateSubreddits',\n",
    "    'traaaaaaannnnnnnnnns',\n",
    "    'trans',\n",
    "    'GenderCynical',\n",
    "    'EnoughTrumpSpam',\n",
    "    'ABoringDystopia',\n",
    "    'pointlesslygendered',\n",
    "    'Persecutionfetish',\n",
    "    'TheRightCantMeme',\n",
    "    'MurderedByAOC',\n",
    "    'LateStageCapitalism',\n",
    "    'TheBluePill',\n",
    "    'justneckbeardthings',\n",
    "    'NotHowGirlsWork',\n",
    "    'CapitalismSux',\n",
    "    'GreenAndPleasant',\n",
    "    'religiousfruitcake',\n",
    "    'FragileWhiteRedditor',\n",
    "    'trumpvirus',\n",
    "    'socialism',\n",
    "    'asktransgender',\n",
    "    'SandersForPresident',\n",
    "    'MtF',\n",
    "    'ftm',\n",
    "    'egg_irl',\n",
    "    'NonBinary',\n",
    "    'HermanCainAward',\n",
    "    'lostgeneration',\n",
    "    'stupidpol',\n",
    "    'Qult_Headquarters',\n",
    "    'IncelTear',\n",
    "    'ParlerWatch',\n",
    "    'ShitLiberalsSay',\n",
    "    'Hasan_Piker',\n",
    "\n",
    "    #right (I think)\n",
    "    'JoeRogan',\n",
    "    'dankmemes',\n",
    "    'Memes_Of_The_Dank',\n",
    "    'okbuddyretard',\n",
    "    'okmatewanker',\n",
    "    'pussypassdenied',\n",
    "    'antifeminists',\n",
    "    'MensRights',\n",
    "    'ProudMaleFeminists',\n",
    "    'WhereAreTheFeminists',\n",
    "    'FeminismUncensored',\n",
    "    'SRSsucks',\n",
    "    'Conservative',\n",
    "    'JordanPeterson',\n",
    "    'conspiracy',\n",
    "    'conspiracy_commons',\n",
    "    'tucker_carlson',\n",
    "    'TheTrumpZone',\n",
    "    'LouderWithCrowder',\n",
    "    'Libertarian',\n",
    "    'AskThe_Donald',\n",
    "    'walkaway',\n",
    "    'ConservativesOnly',\n",
    "    'IncelsCircleJerk',\n",
    "    'BlackPillScience',\n",
    "    'Blubber_Whaling',\n",
    "    'memegender',\n",
    "    'SocialJusticeInAction',\n",
    "    'FreeSpeech',\n",
    "    'libsofreddit',\n",
    "    'EnoughCommieSpam',\n",
    "    'TheLeftCantMeme',\n",
    "    'Anarcho_Capitalism',\n",
    "    'ar15',\n",
    "    'guns',\n",
    "    'nra',\n",
    "    'Firearms',\n",
    "    'CCW',\n",
    "    'Glocks',\n",
    "    'tacticalgear',\n",
    "    'liberalgunowners',\n",
    "    'HillaryForPrison',\n",
    "    'Offensivejokes'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheRedPill\n",
      "BlackPeopleTwitter\n",
      "WhitePeopleTwitter\n",
      "politics\n",
      "law\n",
      "news\n",
      "worldnews\n",
      "Jokes\n",
      "funny\n",
      "gaming\n",
      "Games\n",
      "technology\n",
      "tech\n",
      "technews\n",
      "gadgets\n",
      "space\n",
      "science\n",
      "nextfuckinglevel\n",
      "MurderedByWords\n",
      "mildlyinteresting\n",
      "Damnthatsinteresting\n",
      "mildlyinfuriating\n",
      "wallstreetbets\n",
      "Superstonk\n",
      "shitposting\n",
      "pcmasterrace\n",
      "teenagers\n",
      "PublicFreakout\n",
      "memes\n",
      "AskReddit\n",
      "AskAnAmerican\n",
      "GamingCircleJerk\n",
      "nottheonion\n",
      "gatesopencomeonin\n",
      "wholesomememes\n",
      "wholesome\n",
      "interestingasfuck\n",
      "PoliticalCompassMemes\n",
      "PoliticalHumor\n",
      "AskMen\n",
      "AskWomen\n",
      "TooAfraidToAsk\n",
      "MadeMeSmile\n",
      "rareinsults\n",
      "UFOs\n",
      "HighStrangeness\n",
      "todayilearned\n",
      "RoastMe\n",
      "CryptoCurrency\n",
      "Wellthatsucks\n",
      "barstoolsports\n",
      "awfuleverything\n",
      "unpopularopinion\n",
      "atheism\n",
      "Christianity\n",
      "Catholicism\n",
      "changemyview\n",
      "Coronavirus\n",
      "covid19\n",
      "coronavirusnyc\n",
      "Masks4All\n",
      "consipiratard\n",
      "environment\n",
      "TrollXChromosomes\n",
      "TrollYChromosome\n",
      "WikiLeaks\n",
      "4chan\n",
      "greentext\n",
      "NoStupidQuestions\n",
      "offmychest\n",
      "texas\n",
      "terriblefacebookmemes\n",
      "insanepeoplefacebook\n",
      "ShitMomGroupsSay\n",
      "masskillers\n",
      "Parenting\n",
      "Marriage\n",
      "neoliberal\n",
      "spacex\n",
      "savedyouaclick\n",
      "socialmedia\n",
      "moderatepolitics\n",
      "virginvschad\n",
      "CoronavirusCircleJerk\n",
      "antiwork\n",
      "Anticonsumption\n",
      "SelfAwarewolves\n",
      "niceguys\n",
      "onejoke\n",
      "Feminism\n",
      "WitchesVsPatriarchy\n",
      "AreTheStraightsOK\n",
      "ToiletPaperUSA\n",
      "LeopardsAteMyFace\n",
      "TwoXChromosomes\n",
      "Anarchism\n",
      "TopMindsOfReddit\n",
      "esist\n",
      "MarchAgainstNazis\n",
      "exredpill\n",
      "MensLib\n",
      "lgbt\n",
      "gay\n",
      "bisexual\n",
      "AgainstHateSubreddits\n",
      "traaaaaaannnnnnnnnns\n",
      "trans\n",
      "GenderCynical\n",
      "EnoughTrumpSpam\n",
      "ABoringDystopia\n",
      "pointlesslygendered\n",
      "Persecutionfetish\n",
      "TheRightCantMeme\n",
      "MurderedByAOC\n",
      "LateStageCapitalism\n",
      "TheBluePill\n",
      "justneckbeardthings\n",
      "NotHowGirlsWork\n",
      "CapitalismSux\n",
      "GreenAndPleasant\n",
      "religiousfruitcake\n",
      "FragileWhiteRedditor\n",
      "trumpvirus\n",
      "socialism\n",
      "asktransgender\n",
      "SandersForPresident\n",
      "MtF\n",
      "ftm\n",
      "egg_irl\n",
      "NonBinary\n",
      "HermanCainAward\n",
      "lostgeneration\n",
      "stupidpol\n",
      "Qult_Headquarters\n",
      "IncelTear\n",
      "ParlerWatch\n",
      "ShitLiberalsSay\n",
      "Hasan_Piker\n",
      "JoeRogan\n",
      "dankmemes\n",
      "Memes_Of_The_Dank\n",
      "okbuddyretard\n",
      "okmatewanker\n",
      "pussypassdenied\n",
      "antifeminists\n",
      "MensRights\n",
      "ProudMaleFeminists\n",
      "WhereAreTheFeminists\n",
      "FeminismUncensored\n",
      "SRSsucks\n",
      "Conservative\n",
      "JordanPeterson\n",
      "conspiracy\n",
      "conspiracy_commons\n",
      "tucker_carlson\n",
      "TheTrumpZone\n",
      "LouderWithCrowder\n",
      "Libertarian\n",
      "AskThe_Donald\n",
      "walkaway\n",
      "ConservativesOnly\n",
      "IncelsCircleJerk\n",
      "BlackPillScience\n",
      "Blubber_Whaling\n",
      "memegender\n",
      "SocialJusticeInAction\n",
      "FreeSpeech\n",
      "libsofreddit\n",
      "EnoughCommieSpam\n",
      "TheLeftCantMeme\n",
      "Anarcho_Capitalism\n",
      "ar15\n",
      "guns\n",
      "nra\n",
      "Firearms\n",
      "CCW\n",
      "Glocks\n",
      "tacticalgear\n",
      "liberalgunowners\n",
      "HillaryForPrison\n",
      "Offensivejokes\n"
     ]
    }
   ],
   "source": [
    "# Now, lets build a dataframe of the top posts of all the subreddits in this list\n",
    "\n",
    "messy_df = pd.DataFrame()\n",
    "params = {'limit' : 100} # get the top 100 posts || Worth noting that this will not pull more than 100 posts from a single subreddit\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    print(subreddit)\n",
    "\n",
    "    #top posts of all time\n",
    "    response = requests.get(f\"https://oauth.reddit.com/r/{subreddit}/top/?t=all\", headers=headers, params = params)\n",
    "\n",
    "    #TODO: There is a lot of data that isn't being captured here that could be added\n",
    "    for post in response.json()['data']['children']:\n",
    "        messy_df = messy_df.append({\n",
    "            'created_utc' : post['data']['created_utc'],\n",
    "            'subreddit' : post['data']['subreddit'],\n",
    "            'subreddit_subscribers' : post['data']['subreddit_subscribers'],\n",
    "            'title' : post['data']['title'],\n",
    "            'text' : post['data']['selftext'],\n",
    "            'upvote_ratio' : post['data']['upvote_ratio'],\n",
    "            'num_comments' : post['data']['num_comments'],\n",
    "            'url' : post['data']['url'] # this is just a url link to picture media\n",
    "        }, ignore_index = True)\n",
    "\n",
    "    #top posts this year\n",
    "    response = requests.get(f\"https://oauth.reddit.com/r/{subreddit}/top/?t=year\", headers=headers, params = params)\n",
    "\n",
    "    for post in response.json()['data']['children']:\n",
    "        messy_df = messy_df.append({\n",
    "            'created_utc' : post['data']['created_utc'],\n",
    "            'subreddit' : post['data']['subreddit'],\n",
    "            'subreddit_subscribers' : post['data']['subreddit_subscribers'],\n",
    "            'title' : post['data']['title'],\n",
    "            'text' : post['data']['selftext'],\n",
    "            'upvote_ratio' : post['data']['upvote_ratio'],\n",
    "            'num_comments' : post['data']['num_comments'],\n",
    "            'url' : post['data']['url'] # this is just a url link to picture media\n",
    "        }, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheRedPill             200\n",
       "religiousfruitcake     200\n",
       "TheRightCantMeme       200\n",
       "MurderedByAOC          200\n",
       "LateStageCapitalism    200\n",
       "                      ... \n",
       "IncelsCircleJerk       106\n",
       "Blubber_Whaling        101\n",
       "SRSsucks               101\n",
       "memegender              76\n",
       "ProudMaleFeminists      39\n",
       "Name: subreddit, Length: 180, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Subreddits: 180\n",
      "Total Posts: 35131\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Subreddits: {len(messy_df['subreddit'].value_counts())}\")\n",
    "print(f\"Total Posts: {len(messy_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_df['image?'] = messy_df['url'].apply(lambda x: ('jpg' in x) or ('png' in x) or ('jpeg' in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    34523\n",
       "True       608\n",
       "Name: url, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_df['url'].apply(lambda x: ('gif' in x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     20263\n",
       "False    14868\n",
       "Name: image?, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_df['image?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    35131\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_df['title'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    35131\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_df['text'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agcwi\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2918: DecompressionBombWarning: Image size (121484484 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "c:\\Users\\agcwi\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2918: DecompressionBombWarning: Image size (117331669 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Image processing: do on windows machine because tessaract only runs on linux and windows\n",
    "pytesseract.pytesseract.tesseract_cmd =  r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "image_text = []\n",
    "\n",
    "for index, row in messy_df.iterrows():\n",
    "    if row['image?']:\n",
    "        try:\n",
    "            response = requests.get(row['url'])\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image_string = pytesseract.image_to_string(image)\n",
    "        except:\n",
    "            image_string = ''\n",
    "    else:\n",
    "        image_string = ''\n",
    "\n",
    "    image_text.append(image_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_df['image_text'] = image_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(messy_df, '../data/messy_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c7ae5ca7afa47d1c118e1cc9ccaf65a17609b650c517e098aee76b19a0109a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
